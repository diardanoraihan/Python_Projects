{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = center>PART 1: UNDERSTANDING AND VISUALIZING DATA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Statistics: Definition\n",
    "- Methodological: tools and methods for working with and understanding data.\n",
    "- Statisticians: apply and develop data analysis methods, seek to understand their properties.\n",
    "- Researchers and workers: apply and extend statistical methodology, and contribute new ideas and methods for conducting data analysis.\n",
    "\n",
    "__A Statistic and the field of Statistics__:\n",
    "- A statistic: numerical or graphical summary of a collection of data. \n",
    "    - Average score on final exam\n",
    "    - Minimum temperature at a location over year\n",
    "    - Proportion of people who are retired\n",
    "- Statistics: academic discipline focusing on research methodology. Statisticians develp new statistical tools, calculate statistics from data, and collaborate with subject-mater experts to interpret them. \n",
    "\n",
    "__The Landscape of Statistics__:\n",
    "Evolving and dynamic field ~ Emerging challanges and opportunities: \n",
    "- Properties of statistical methods are under continuing study. \n",
    "- New application areas -> development of new analytic methods. \n",
    "- New types of sensors -> new types of data\n",
    "- Advances in computing -> sophisticated analyses on Big Data\n",
    "\n",
    "__Statistics and its Allied Fields__: \n",
    "- __Computer Science__\n",
    "    - algorithms, data structures for working with data, programming languages for manipulating data\n",
    "- __Mathematics__\n",
    "    - language and notation for expressing statistical concepts concisely, tools for understanding properties of statistical methods\n",
    "- __Probability Theory__\n",
    "    - branch of mathematics ~ crucial part of foundations of statistics - to express ideas about randomness and uncertainty\n",
    "- __Data Science__\n",
    "    - database management, machine learning, computational infrastructure to carry out data analysis.\n",
    "- __Artificial Intelligence__\n",
    "    - Statistics now is a major linchpin in research and industry. A number of different emerging applications include:\n",
    "        - Computer Vision\n",
    "        - Automated Driving\n",
    "        - Recommender system\n",
    "        - Precision medicine\n",
    "        - Fraud Detection\n",
    "        - Job training and behavioral therapy\n",
    "        - etc.\n",
    "\n",
    "## 1.2 Statistics: Perspectives\n",
    "\n",
    "__The Art of Summarizing__\n",
    "\n",
    "- Data can be overwhelming\n",
    "- Making sense of data usually involves reduction and summarization\n",
    "    - reduction: make a dataset comprehensible to human observer\n",
    "    - summarization: always depends primarily on goals of __data consumer__ to be meaningful -- many approaches\n",
    "    \n",
    "__Science of Uncertainty__\n",
    "- Data can be misleading.\n",
    "- Statistics provides framework for assessing whether claims based on data are meaningful. \n",
    "- Uncertainty is inevitable, but it is highly desirable to quantify how far our reported findings may fall from __the truth__. \n",
    "- I.e. many public opinion polls report results along with a margin of error to provide an idea of what that potential discrepancy wll be between the reported and the actual states of public opinion.\n",
    "\n",
    "__Science of Decisions__\n",
    "- Understanding data is important -> only consequential if we act on what we have learned.\n",
    "- __Desicion-making__ = ultimate goal of any statistical analysis.\n",
    "- We make decisions in face of __uncertainty!__\n",
    "    - What are costs and benefits of different approaches? \n",
    "    \n",
    "__Science of Variation__\n",
    "- Often focus on most typical or __central__ value.\n",
    "    - i.e. Average American has around \\$6000 of credit card debt (central value of credit card debt in US population)\n",
    "- Great emphasis on understanding __variation__ in data!\n",
    "    - i.e. 10% of Americans have more than $30,000 in credit card debt (variation of credit card in US population)\n",
    "\n",
    "__Art of Forecasting__\n",
    "- Forecasting or prediction = central tasks in statistics\n",
    "- Cannot know future with absolute certainty, but efficient use of available data\n",
    "    - it can sometimes make accurate predictions about future!\n",
    "    \n",
    "__Science of Measurement__\n",
    "- __High accuracy__: person's age or height\n",
    "- __More difficult__: blodd pressure (varies in minute to minute)\n",
    "- __Harder__: \"mood\", \"political ideology\", \"personality\"\n",
    "\n",
    "__Basis for Principled Data Collection__\n",
    "- Data often expensive and difficult to collect\n",
    "- Resource limitations -> collect least data possible\n",
    "- __Statistics__: provides a rational way to manage this tread-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Types\n",
    "\n",
    "__Data can be:__ \n",
    "- numbers\n",
    "- images\n",
    "- words\n",
    "- audio\n",
    "\n",
    "__Two key types of Data:__\n",
    "- __Organic / Process Data__\n",
    "    - Generated by a computerized information system (from image/audio recordings), ie:\n",
    "        - Financial or Point-of-sale transactions/Stock market exchanges, \n",
    "        - Netflix viewing history, \n",
    "        - Web browser activity, \n",
    "        - Sporting event\n",
    "        - Temperature/pollution sensors\n",
    "    - These processes generate massive quantities of data -> __Big Data__\n",
    "    - Processing requires significant computational resources; data scientist \"mine\" these data to study trends and uncover interesting relationship.\n",
    "    \n",
    "    \n",
    "- __\"Designed\" Data Collection__\n",
    "    - Designed to specifically address astated research objective\n",
    "        - Individuals sampled from a population, interviewed about opinions on a particular topic.\n",
    "    - Common features of \"designed\" data: \n",
    "        - __Sampling from populations__ - administration of carefully designed questions.\n",
    "        - Typically __data sets much smaller__ compared to organic/process data sets.\n",
    "        - __Data collected for very specific reasons__, rather than simple reflections of ongoing natural process.\n",
    "\n",
    "__Are the Data i.i.d?__\n",
    "- For analyzing data, regardless of source, an important questions: \n",
    "    - __Can the data be considered i.i.d?__\n",
    "        - i: __independent__ -> all observations are independent of all the other observations (there are no correlations)\n",
    "        - id: __identically distributed__ -> the values that we're looking at are all arising from some common statistical distribution\n",
    "    - i.e.: __Final exam scores__ from a large class at a university are __independent observations__ from a __common normal distribution__.\n",
    "        - Each student is treated independently that are coming from a common normal distribution, we look at the entire distribution of exam scores it might look like this kind of bell-shaped curve.\n",
    "\n",
    "\n",
    "- __If yes__, we can inspect the features of that distribution and make inference about those features:\n",
    "    - mean, variance, extreme percentile. \n",
    "    - the overall mean in a population, the overall extreme percentile of a population.\n",
    "    \n",
    "\n",
    "- __If not__? These are the example scenarios: \n",
    "    - Students sitting next to each other tend to have similar scores\n",
    "    - Males and females might have different means\n",
    "    - Students form same discussion sections may have similar scores\n",
    "\n",
    "> Conclusion: __Dependencies and differences need to be accounted for in analysis!__ -> Need different analytic procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Variable Types\n",
    "\n",
    "For this material, we will look at the __NHANES__ Data (National Health and Nutrition Examination Survey) to assess the health and nutrition of children and adults in the US. \n",
    "\n",
    "__Quantitative Variables__\n",
    "- Numerical, measurable quantities in which arithmetic operations often make sense.\n",
    "    - __Continuous__ - could take on any value within an interval, many possible values\n",
    "    - __Discrete__ - countable value, finite number of values\n",
    "\n",
    "\n",
    "__Qualitative (Catagorical) Variables__\n",
    "- Classifies individuals or items into different groups.\n",
    "    - __Ordinal__ - groups have an order or ranking (Senior/junior, January/February/. . ., etc)\n",
    "    - __Nominal__ - groups are merely names, no ranking (race, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age adult\n",
       "0   22   yes\n",
       "1   14    no\n",
       "2   44   yes\n",
       "3   14    no\n",
       "4   30   yes"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_ex = pd.DataFrame([[22, 'yes'], [14, 'no'], [44, 'yes'], [14, 'no'], [30, 'yes']], columns = ['age', 'adult'])\n",
    "df_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>adult</th>\n",
       "      <th>adult_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age adult  adult_num\n",
       "0   22   yes          1\n",
       "1   14    no          0\n",
       "2   44   yes          1\n",
       "3   14    no          0\n",
       "4   30   yes          1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ex['adult_num'] = df_ex['adult'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "df_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that we can take an average of the age in our sample, but we cannot take an average of adult_num because it does not make sense to have continuous number in adult_num variable because simply the adult is categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Study Design\n",
    "__Examples__:\n",
    "- __Clinical__ trials for drugs and other medical treatments\n",
    "- __Reliability__ and __quality-assurance__ studies for manufactured products\n",
    "- Observational studies for __human health__\n",
    "- __Public opinion__ and other surveys\n",
    "- Studies involving __administrative__ and other incidental data\n",
    "- __Market research__ studies\n",
    "- __Agricultural__ field trials\n",
    "\n",
    "__Types of Research Studies__:\n",
    "- Exploratory vs Confirmatory studies\n",
    "    - Confimatory: scientific method ~ specify __falsifiable hypothesis__\n",
    "- Comparative vs Non-Comparative studies\n",
    "- Observational studies vs Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
