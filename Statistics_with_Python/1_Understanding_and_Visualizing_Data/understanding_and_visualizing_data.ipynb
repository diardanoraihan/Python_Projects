{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = center>PART 1: UNDERSTANDING AND VISUALIZING DATA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Statistics: Definition\n",
    "- Methodological: tools and methods for working with and understanding data.\n",
    "- Statisticians: apply and develop data analysis methods, seek to understand their properties.\n",
    "- Researchers and workers: apply and extend statistical methodology, and contribute new ideas and methods for conducting data analysis.\n",
    "\n",
    "__A Statistic and the field of Statistics__:\n",
    "- A statistic: numerical or graphical summary of a collection of data. \n",
    "    - Average score on final exam\n",
    "    - Minimum temperature at a location over year\n",
    "    - Proportion of people who are retired\n",
    "- Statistics: academic discipline focusing on research methodology. Statisticians develp new statistical tools, calculate statistics from data, and collaborate with subject-mater experts to interpret them. \n",
    "\n",
    "__The Landscape of Statistics__:\n",
    "Evolving and dynamic field ~ Emerging challanges and opportunities: \n",
    "- Properties of statistical methods are under continuing study. \n",
    "- New application areas -> development of new analytic methods. \n",
    "- New types of sensors -> new types of data\n",
    "- Advances in computing -> sophisticated analyses on Big Data\n",
    "\n",
    "__Statistics and its Allied Fields__: \n",
    "- __Computer Science__\n",
    "    - algorithms, data structures for working with data, programming languages for manipulating data\n",
    "- __Mathematics__\n",
    "    - language and notation for expressing statistical concepts concisely, tools for understanding properties of statistical methods\n",
    "- __Probability Theory__\n",
    "    - branch of mathematics ~ crucial part of foundations of statistics - to express ideas about randomness and uncertainty\n",
    "- __Data Science__\n",
    "    - database management, machine learning, computational infrastructure to carry out data analysis.\n",
    "- __Artificial Intelligence__\n",
    "    - Statistics now is a major linchpin in research and industry. A number of different emerging applications include:\n",
    "        - Computer Vision\n",
    "        - Automated Driving\n",
    "        - Recommender system\n",
    "        - Precision medicine\n",
    "        - Fraud Detection\n",
    "        - Job training and behavioral therapy\n",
    "        - etc.\n",
    "\n",
    "## 1.2 Statistics: Perspectives\n",
    "\n",
    "__The Art of Summarizing__\n",
    "\n",
    "- Data can be overwhelming\n",
    "- Making sense of data usually involves reduction and summarization\n",
    "    - reduction: make a dataset comprehensible to human observer\n",
    "    - summarization: always depends primarily on goals of __data consumer__ to be meaningful -- many approaches\n",
    "    \n",
    "__Science of Uncertainty__\n",
    "- Data can be misleading.\n",
    "- Statistics provides framework for assessing whether claims based on data are meaningful. \n",
    "- Uncertainty is inevitable, but it is highly desirable to quantify how far our reported findings may fall from __the truth__. \n",
    "- I.e. many public opinion polls report results along with a margin of error to provide an idea of what that potential discrepancy wll be between the reported and the actual states of public opinion.\n",
    "\n",
    "__Science of Decisions__\n",
    "- Understanding data is important -> only consequential if we act on what we have learned.\n",
    "- __Desicion-making__ = ultimate goal of any statistical analysis.\n",
    "- We make decisions in face of __uncertainty!__\n",
    "    - What are costs and benefits of different approaches? \n",
    "    \n",
    "__Science of Variation__\n",
    "- Often focus on most typical or __central__ value.\n",
    "    - i.e. Average American has around \\$6000 of credit card debt (central value of credit card debt in US population)\n",
    "- Great emphasis on understanding __variation__ in data!\n",
    "    - i.e. 10% of Americans have more than $30,000 in credit card debt (variation of credit card in US population)\n",
    "\n",
    "__Art of Forecasting__\n",
    "- Forecasting or prediction = central tasks in statistics\n",
    "- Cannot know future with absolute certainty, but efficient use of available data\n",
    "    - it can sometimes make accurate predictions about future!\n",
    "    \n",
    "__Science of Measurement__\n",
    "- __High accuracy__: person's age or height\n",
    "- __More difficult__: blodd pressure (varies in minute to minute)\n",
    "- __Harder__: \"mood\", \"political ideology\", \"personality\"\n",
    "\n",
    "__Basis for Principled Data Collection__\n",
    "- Data often expensive and difficult to collect\n",
    "- Resource limitations -> collect least data possible\n",
    "- __Statistics__: provides a rational way to manage this tread-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Types\n",
    "\n",
    "__Data can be:__ \n",
    "- numbers\n",
    "- images\n",
    "- words\n",
    "- audio\n",
    "\n",
    "__Two key types of Data:__\n",
    "- __Organic / Process Data__\n",
    "    - Generated by a computerized information system (from image/audio recordings), ie:\n",
    "        - Financial or Point-of-sale transactions/Stock market exchanges, \n",
    "        - Netflix viewing history, \n",
    "        - Web browser activity, \n",
    "        - Sporting event\n",
    "        - Temperature/pollution sensors\n",
    "    - These processes generate massive quantities of data -> __Big Data__\n",
    "    - Processing requires significant computational resources; data scientist \"mine\" these data to study trends and uncover interesting relationship.\n",
    "    \n",
    "    \n",
    "- __\"Designed\" Data Collection__\n",
    "    - Designed to specifically address astated research objective\n",
    "        - Individuals sampled from a population, interviewed about opinions on a particular topic.\n",
    "    - Common features of \"designed\" data: \n",
    "        - __Sampling from populations__ - administration of carefully designed questions.\n",
    "        - Typically __data sets much smaller__ compared to organic/process data sets.\n",
    "        - __Data collected for very specific reasons__, rather than simple reflections of ongoing natural process.\n",
    "\n",
    "__Are the Data i.i.d?__\n",
    "- For analyzing data, regardless of source, an important questions: \n",
    "    - __Can the data be considered i.i.d?__\n",
    "        - i: __independent__ -> all observations are independent of all the other observations (there are no correlations)\n",
    "        - id: __identically distributed__ -> the values that we're looking at are all arising from some common statistical distribution\n",
    "    - i.e.: __Final exam scores__ from a large class at a university are __independent observations__ from a __common normal distribution__.\n",
    "        - Each student is treated independently that are coming from a common normal distribution, we look at the entire distribution of exam scores it might look like this kind of bell-shaped curve.\n",
    "\n",
    "\n",
    "- __If yes__, we can inspect the features of that distribution and make inference about those features:\n",
    "    - mean, variance, extreme percentile. \n",
    "    - the overall mean in a population, the overall extreme percentile of a population.\n",
    "    \n",
    "\n",
    "- __If not__? These are the example scenarios: \n",
    "    - Students sitting next to each other tend to have similar scores\n",
    "    - Males and females might have different means\n",
    "    - Students form same discussion sections may have similar scores\n",
    "\n",
    "> Conclusion: __Dependencies and differences need to be accounted for in analysis!__ -> Need different analytic procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Variable Types\n",
    "\n",
    "For this material, we will look at the __NHANES__ Data (National Health and Nutrition Examination Survey) to assess the health and nutrition of children and adults in the US. \n",
    "\n",
    "__Quantitative Variables__\n",
    "- Numerical, measurable quantities in which arithmetic operations often make sense.\n",
    "    - __Continuous__ - could take on any value within an interval, many possible values\n",
    "    - __Discrete__ - countable value, finite number of values\n",
    "\n",
    "\n",
    "__Qualitative (Catagorical) Variables__\n",
    "- Classifies individuals or items into different groups.\n",
    "    - __Ordinal__ - groups have an order or ranking (Senior/junior, January/February/. . ., etc)\n",
    "    - __Nominal__ - groups are merely names, no ranking (race, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age adult\n",
       "0   22   yes\n",
       "1   14    no\n",
       "2   44   yes\n",
       "3   14    no\n",
       "4   30   yes"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [[22, 'yes'], [14, 'no'], [44, 'yes'], [14, 'no'], [30, 'yes']]\n",
    "df_ex = pd.DataFrame(data, columns = ['age', 'adult'])\n",
    "df_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>adult</th>\n",
       "      <th>adult_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age adult  adult_num\n",
       "0   22   yes          1\n",
       "1   14    no          0\n",
       "2   44   yes          1\n",
       "3   14    no          0\n",
       "4   30   yes          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ex['adult_num'] = df_ex['adult'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "df_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that we can take an average of the `age` in our sample, but we cannot take an average of `adult_num` because it does not make sense to have continuous number in adult_num variable because simply the adult is categorical variable.\n",
    "\n",
    "\n",
    "- Now, let's connect these variable types to the __data types in python__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Data Types in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical or Quantitative\n",
    ">  _Taking the mean make sense!_\n",
    "- Discrete\n",
    "    - Integer (int) # Stored exactly\n",
    "- Continuous\n",
    "    - Float (float) # Stored simirarly to scientific notation representation. Allos for decimal places, but loses precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Integer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "3.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try taking the mean\n",
    "\n",
    "import numpy as np\n",
    "numbers = [2,3,4,5]\n",
    "print(sum(numbers)/len(numbers))\n",
    "print(np.mean(numbers))\n",
    "type(sum(numbers)/len(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Float__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(3/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "print(np.round(6*10**(-1), 1))\n",
    "print(6*10**(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see if we don't round it, we will have a bunch of zeros. This is how floats are stored in our machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(6*10**(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although 4.0 is a whole number, because we've said to store this to account a decimal point, then the type of it also a float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical or Qualitative\n",
    "> _Taking the mean does not make sense!_\n",
    "- Nominal\n",
    "    - Boolean (bool)\n",
    "    - String (str)\n",
    "    - None (Nonetype)\n",
    "- Ordinal\n",
    "    - Only defined by how you use the data\n",
    "    - Often important when creating visuals\n",
    "    - Lists can hold ordinal information because they have indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Boolean__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean\n",
    "type(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No :(\n"
     ]
    }
   ],
   "source": [
    "# Boolean\n",
    "if 6 < 5:\n",
    "    print('Yes :)')\n",
    "else: \n",
    "    print('No :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n",
      "<class 'bool'>\n",
      "<class 'bool'>\n",
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "myList = [True, 6<5, 1==3, None is None]\n",
    "for element in myList: \n",
    "    print(type(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(myList)/len(myList))\n",
    "type(sum(myList)/len(myList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since boolean holds value of 0 for `False` and 1 for `True`, the mean above isn't necessarily the mean of `myList`, but the mean of how many are true vs how many are false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__String__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"this is a string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"3.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strList = ['dog', 'koala']\n",
    "type(strList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nonetype__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None\n",
    "type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = None\n",
    "type(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lists__\n",
    "\n",
    "A list can hold many types and can also be used to strore ordinal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'float'>\n",
      "<class 'str'>\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "myList = [1,1.1, \"This is a sentence\", None]\n",
    "for element in myList: \n",
    "    print(type(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'third'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList = ['third', 'first', 'medium', 'small', 'large']\n",
    "myList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'large', 'medium', 'small', 'third']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList.sort()\n",
    "myList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Study Design\n",
    "__Examples__:\n",
    "- __Clinical__ trials for drugs and other medical treatments\n",
    "- __Reliability__ and __quality-assurance__ studies for manufactured products\n",
    "- Observational studies for __human health__\n",
    "- __Public opinion__ and other surveys\n",
    "- Studies involving __administrative__ and other incidental data\n",
    "- __Market research__ studies\n",
    "- __Agricultural__ field trials\n",
    "\n",
    "__Types of Research Studies__:\n",
    "- __Exploratory__ vs __Confirmatory__ studies\n",
    "    - <u>Confimatory</u>: scientific method ~ specify __falsifiable hypothesis__, then test it -> collect data to address single pre-specified question.\n",
    "    - <u>Exploratory</u>: collect and analyze data without first pre-specifying question.\n",
    "    \n",
    "    Note: informative but __watch out__ for __\"overfitting\"__, __\"multiple testing\"__, __\"p-hacking\"__. The more questions you ask from a dataset, the more likely you are to draw a misleading conclusions.\n",
    "    \n",
    "    \n",
    "- __Comparative__ vs __Non-Comparative__ studies\n",
    "    - <u>Comparative</u>: goal -> __contrast__ one quantity to another ~ many research studies are comparative in nature.\n",
    "    - <u>Non-Comparative</u>: focus -> __estimating__ or __predicting__ absolute quantities ~ not (explicitly) comparative.\n",
    "    \n",
    "    \n",
    "- __Observational__ vs __Experiments__ studies\n",
    "    - <u>Observational</u>: arise \"naturally\", contrasts based on \"self-selection\" of units into groups. It often says subjects are \"exposed\" to a condition rather than being \"assigned\" _(passive or self-selected, used when impractical or unethical to assign)_.\n",
    "        - to identify the health effects such as lifespan, lung cancer status between smokers vs non-smokers\n",
    "        - to identify the impact on teaching experience on student learning by comparing standardized test scores betwen students that are in classrooms with teachers that have less experience to the scores for students in classrooms where the teachers have more experience.\n",
    "    - <u>Experiments</u>: involve manipulation or random assignmnet of subject to \"treatment arms\" -> experimenter deliberately treats different units in different ways.\n",
    "        - to compare the yield of lettuce in fields that are treated with and without fertilizer.\n",
    "        - to assess whether people are more likely to click on one of two versions of an online ad, we can randomly expose people one version or the other and then compare those click rates. \n",
    "        \n",
    "\n",
    "__Power and Bias__\n",
    "- __Power Analysis__: \n",
    "    - Process to assess whether given study design likely to yield meaningful findings. \n",
    "- __Bias__: \n",
    "    - Measurements that are systematically off-target, or sample is not representative of population of interest. _Observational studies are especially vulnerable to it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
